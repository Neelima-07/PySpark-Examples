{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[1]\") \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ncolumns = [\"name\",\"languagesAtSchool\",\"currentState\"]\ndata = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \\\n    (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"), \\\n    (\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n\ndf = spark.createDataFrame(data=data,schema=columns)\ndf.printSchema()\ndf.show(truncate=False)\n\nfrom pyspark.sql.functions import col, concat_ws\ndf2 = df.withColumn(\"languagesAtSchool\",\n   concat_ws(\",\",col(\"languagesAtSchool\")))\ndf2.printSchema()\ndf2.show(truncate=False)\n\n\ndf.createOrReplaceTempView(\"ARRAY_STRING\")\nspark.sql(\"select name, concat_ws(',',languagesAtSchool) as languagesAtSchool,currentState from ARRAY_STRING\").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f130c780-4ffe-454d-b370-6178cd9a846d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- languagesAtSchool: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- currentState: string (nullable = true)\n\n+----------------+------------------+------------+\n|name            |languagesAtSchool |currentState|\n+----------------+------------------+------------+\n|James,,Smith    |[Java, Scala, C++]|CA          |\n|Michael,Rose,   |[Spark, Java, C++]|NJ          |\n|Robert,,Williams|[CSharp, VB]      |NV          |\n+----------------+------------------+------------+\n\nroot\n |-- name: string (nullable = true)\n |-- languagesAtSchool: string (nullable = false)\n |-- currentState: string (nullable = true)\n\n+----------------+-----------------+------------+\n|name            |languagesAtSchool|currentState|\n+----------------+-----------------+------------+\n|James,,Smith    |Java,Scala,C++   |CA          |\n|Michael,Rose,   |Spark,Java,C++   |NJ          |\n|Robert,,Williams|CSharp,VB        |NV          |\n+----------------+-----------------+------------+\n\n+----------------+-----------------+------------+\n|name            |languagesAtSchool|currentState|\n+----------------+-----------------+------------+\n|James,,Smith    |Java,Scala,C++   |CA          |\n|Michael,Rose,   |Spark,Java,C++   |NJ          |\n|Robert,,Williams|CSharp,VB        |NV          |\n+----------------+-----------------+------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Import the necessary modules from the pyspark.sql package.\n#Create a SparkSession named 'SparkByExamples.com'.\n#Define the column names and sample data for the DataFrame.\n#Create the DataFrame df using the provided data and schema.\n#Print the schema of the DataFrame using the printSchema() method.\n#Display the contents of the DataFrame using the show() method.\n#Import the necessary functions (col, concat_ws) from pyspark.sql.functions.\n#Use withColumn() to transform the \"languagesAtSchool\" column by concatenating the array elements into a single string separated by commas. Assign the transformed DataFrame to df2.\n#Print the schema of df2 using the printSchema() method.\n#Display the contents of df2 using the show() method.\n#Register df as a temporary view named \"ARRAY_STRING\" using createOrReplaceTempView().\n#Execute a SQL query using Spark SQL to select the \"name\", transformed \"languagesAtSchool\", and \"currentState\" columns from the \"ARRAY_STRING\" view. The concat_ws() function is used in the SQL query to perform the same transformation as in step 8. The result is displayed using the show() method.\n#The main focus of this code is to showcase two different ways to concatenate array elements into a single string using concat_ws(): one using DataFrame functions and another using Spark SQL.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aafef18e-0ff4-476f-abb2-1b5b12e35356","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-array-string.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
