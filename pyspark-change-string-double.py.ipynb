{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import DoubleType, IntegerType\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\nsimpleData = [(\"James\",\"34\",\"true\",\"M\",\"3000.6089\"),\n    (\"Michael\",\"33\",\"true\",\"F\",\"3300.8067\"),\n    (\"Robert\",\"37\",\"false\",\"M\",\"5000.5034\")\n  ]\n\ncolumns = [\"firstname\",\"age\",\"isGraduated\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data = simpleData, schema = columns)\ndf.printSchema()\ndf.show(truncate=False)\n\nfrom pyspark.sql.functions import col,round,expr\ndf.withColumn(\"salary\",df.salary.cast('double')).printSchema()    \ndf.withColumn(\"salary\",df.salary.cast(DoubleType())).printSchema()    \ndf.withColumn(\"salary\",col(\"salary\").cast('double')).printSchema()    \n\n#df.withColumn(\"salary\",round(df.salary.cast(DoubleType()),2)).show(truncate=False).printSchema()    \ndf.selectExpr(\"firstname\",\"isGraduated\",\"cast(salary as double) salary\").printSchema()    \n\ndf.createOrReplaceTempView(\"CastExample\")\nspark.sql(\"SELECT firstname,isGraduated,DOUBLE(salary) as salary from CastExample\").printSchema()\n\n\n#df.select(\"firstname\",expr(df.age),\"isGraduated\",col(\"salary\").cast('float').alias(\"salary\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f2962d7d-5ddb-403b-8316-233d7d0ee1f4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- firstname: string (nullable = true)\n |-- age: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: string (nullable = true)\n\n+---------+---+-----------+------+---------+\n|firstname|age|isGraduated|gender|salary   |\n+---------+---+-----------+------+---------+\n|James    |34 |true       |M     |3000.6089|\n|Michael  |33 |true       |F     |3300.8067|\n|Robert   |37 |false      |M     |5000.5034|\n+---------+---+-----------+------+---------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- age: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: double (nullable = true)\n\nroot\n |-- firstname: string (nullable = true)\n |-- age: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: double (nullable = true)\n\nroot\n |-- firstname: string (nullable = true)\n |-- age: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: double (nullable = true)\n\nroot\n |-- firstname: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- salary: double (nullable = true)\n\nroot\n |-- firstname: string (nullable = true)\n |-- isGraduated: string (nullable = true)\n |-- salary: double (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Import the necessary modules: SparkSession from pyspark.sql and DoubleType, IntegerType from pyspark.sql.types.\n#Create a SparkSession named 'SparkByExamples.com' using SparkSession.builder.appName('SparkByExamples.com').getOrCreate().\n#Define the simple data as a list of tuples, where each tuple represents a row in the DataFrame.\n#Define the column names for the DataFrame.\n#Create the DataFrame df using the provided data and schema using spark.createDataFrame(data=simpleData, schema=columns).\n#Print the schema of the DataFrame using the printSchema() method.\n#Display the contents of the DataFrame using the show() method.\n#Import the necessary functions: col, round, expr from pyspark.sql.functions.\n#Use withColumn() to apply casting operations on the \"salary\" column of the DataFrame. You can use either a string representation or DoubleType() to specify the target data type. However, in the given code, the result of these operations is not assigned to any variable or printed.\n#Use selectExpr() to cast the \"salary\" column to double using SQL-like expressions, while keeping other columns intact. The result is printed using printSchema().\n#Create a temporary view named \"CastExample\" for the DataFrame df using createOrReplaceTempView().\n#Use spark.sql() to run a SQL query that casts the \"salary\" column to double and select the \"firstname\" and \"isGraduated\" columns. The result is printed using printSchema().\n#It seems that there are some commented lines that may have been intended to perform casting operations and show the resulting DataFrame. However, those lines are currently commented out.\n\n#If you want to execute the commented lines, you can uncomment them and remove the printSchema() statement at the end of each line to display the DataFrame instead.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98483aa6-3b82-459d-ba2c-5b89e314d4f2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-change-string-double.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
