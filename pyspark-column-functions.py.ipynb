{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata=[(\"James\",\"Bond\",\"100\",None),\n      (\"Ann\",\"Varsa\",\"200\",'F'),\n      (\"Tom Cruise\",\"XXX\",\"400\",''),\n      (\"Tom Brand\",None,\"400\",'M')] \ncolumns=[\"fname\",\"lname\",\"id\",\"gender\"]\ndf=spark.createDataFrame(data,columns)\n\n#alias\nfrom pyspark.sql.functions import expr\ndf.select(df.fname.alias(\"first_name\"), \\\n          df.lname.alias(\"last_name\"), \\\n          expr(\" fname ||','|| lname\").alias(\"fullName\") \\\n   ).show()\n\n#asc, desc\ndf.sort(df.fname.asc()).show()\ndf.sort(df.fname.desc()).show()\n\n#cast\ndf.select(df.fname,df.id.cast(\"int\")).printSchema()\n\n#between\ndf.filter(df.id.between(100,300)).show()\n\n#contains\ndf.filter(df.fname.contains(\"Cruise\")).show()\n\n#startswith, endswith()\ndf.filter(df.fname.startswith(\"T\")).show()\ndf.filter(df.fname.endswith(\"Cruise\")).show()\n\n#eqNullSafe\n\n#isNull & isNotNull\ndf.filter(df.lname.isNull()).show()\ndf.filter(df.lname.isNotNull()).show()\n\n#like , rlike\ndf.select(df.fname,df.lname,df.id) \\\n  .filter(df.fname.like(\"%om\")) \n\n#over\n\n#substr\ndf.select(df.fname.substr(1,2).alias(\"substr\")).show()\n\n#when & otherwise\nfrom pyspark.sql.functions import when\ndf.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n              .when(df.gender==\"F\",\"Female\") \\\n              .when(df.gender==None ,\"\") \\\n              .otherwise(df.gender).alias(\"new_gender\") \\\n    ).show()\n\n#isin\nli=[\"100\",\"200\"]\ndf.select(df.fname,df.lname,df.id) \\\n  .filter(df.id.isin(li)) \\\n  .show()\n\nfrom pyspark.sql.types import StructType,StructField,StringType,ArrayType,MapType\ndata=[((\"James\",\"Bond\"),[\"Java\",\"C#\"],{'hair':'black','eye':'brown'}),\n      ((\"Ann\",\"Varsa\"),[\".NET\",\"Python\"],{'hair':'brown','eye':'black'}),\n      ((\"Tom Cruise\",\"\"),[\"Python\",\"Scala\"],{'hair':'red','eye':'grey'}),\n      ((\"Tom Brand\",None),[\"Perl\",\"Ruby\"],{'hair':'black','eye':'blue'})]\n\nschema = StructType([\n        StructField('name', StructType([\n            StructField('fname', StringType(), True),\n            StructField('lname', StringType(), True)])),\n        StructField('languages', ArrayType(StringType()),True),\n        StructField('properties', MapType(StringType(),StringType()),True)\n     ])\ndf=spark.createDataFrame(data,schema)\ndf.printSchema()\n#getItem()\ndf.select(df.languages.getItem(1)).show()\n\ndf.select(df.properties.getItem(\"hair\")).show()\n\n#getField from Struct or Map\ndf.select(df.properties.getField(\"hair\")).show()\n\ndf.select(df.name.getField(\"fname\")).show()\n\n#dropFields\n#from pyspark.sql.functions import col\n#df.withColumn(\"name1\",col(\"name\").dropFields([\"fname\"])).show()\n\n#withField\n#from pyspark.sql.functions import lit\n#df.withColumn(\"name\",df.name.withField(\"fname\",lit(\"AA\"))).show()\n\n#from pyspark.sql import Row\n#from pyspark.sql.functions import lit\n#df = spark.createDataFrame([Row(a=Row(b=1, c=2))])\n#df.withColumn('a', df['a'].withField('b', lit(3))).select('a.b').show()\n        \n#from pyspark.sql import Row\n#from pyspark.sql.functions import col, lit\n#df = spark.createDataFrame([\n#Row(a=Row(b=1, c=2, d=3, e=Row(f=4, g=5, h=6)))])\n#df.withColumn('a', df['a'].dropFields('b')).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f66b16bc-7d09-448b-a493-1254857e59e5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+---------+--------------+\n|first_name|last_name|      fullName|\n+----------+---------+--------------+\n|     James|     Bond|    James,Bond|\n|       Ann|    Varsa|     Ann,Varsa|\n|Tom Cruise|      XXX|Tom Cruise,XXX|\n| Tom Brand|     null|          null|\n+----------+---------+--------------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|       Ann|Varsa|200|     F|\n|     James| Bond|100|  null|\n| Tom Brand| null|400|     M|\n|Tom Cruise|  XXX|400|      |\n+----------+-----+---+------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|Tom Cruise|  XXX|400|      |\n| Tom Brand| null|400|     M|\n|     James| Bond|100|  null|\n|       Ann|Varsa|200|     F|\n+----------+-----+---+------+\n\nroot\n |-- fname: string (nullable = true)\n |-- id: integer (nullable = true)\n\n+-----+-----+---+------+\n|fname|lname| id|gender|\n+-----+-----+---+------+\n|James| Bond|100|  null|\n|  Ann|Varsa|200|     F|\n+-----+-----+---+------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|Tom Cruise|  XXX|400|      |\n+----------+-----+---+------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|Tom Cruise|  XXX|400|      |\n| Tom Brand| null|400|     M|\n+----------+-----+---+------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|Tom Cruise|  XXX|400|      |\n+----------+-----+---+------+\n\n+---------+-----+---+------+\n|    fname|lname| id|gender|\n+---------+-----+---+------+\n|Tom Brand| null|400|     M|\n+---------+-----+---+------+\n\n+----------+-----+---+------+\n|     fname|lname| id|gender|\n+----------+-----+---+------+\n|     James| Bond|100|  null|\n|       Ann|Varsa|200|     F|\n|Tom Cruise|  XXX|400|      |\n+----------+-----+---+------+\n\n+------+\n|substr|\n+------+\n|    Ja|\n|    An|\n|    To|\n|    To|\n+------+\n\n+----------+-----+----------+\n|     fname|lname|new_gender|\n+----------+-----+----------+\n|     James| Bond|      null|\n|       Ann|Varsa|    Female|\n|Tom Cruise|  XXX|          |\n| Tom Brand| null|      Male|\n+----------+-----+----------+\n\n+-----+-----+---+\n|fname|lname| id|\n+-----+-----+---+\n|James| Bond|100|\n|  Ann|Varsa|200|\n+-----+-----+---+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- fname: string (nullable = true)\n |    |-- lname: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+------------+\n|languages[1]|\n+------------+\n|          C#|\n|      Python|\n|       Scala|\n|        Ruby|\n+------------+\n\n+----------------+\n|properties[hair]|\n+----------------+\n|           black|\n|           brown|\n|             red|\n|           black|\n+----------------+\n\n+----------------+\n|properties[hair]|\n+----------------+\n|           black|\n|           brown|\n|             red|\n|           black|\n+----------------+\n\n+----------+\n|name.fname|\n+----------+\n|     James|\n|       Ann|\n|Tom Cruise|\n| Tom Brand|\n+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Import the necessary modules: SparkSession from pyspark.sql.\n\n#Create a SparkSession named 'SparkByExamples.com' using SparkSession.builder.appName('SparkByExamples.com').getOrCreate().\n\n#Define sample data as a list of tuples.\n\n#Define column names for the DataFrame.\n\n#Create the DataFrame using spark.createDataFrame(data, columns).\n\n#Perform different operations on the DataFrame:\n\n#Alias: Use alias() or expr() to assign new column names.\n#Sort: Use sort() with asc() or desc() to sort the DataFrame.\n#Cast: Use cast() to change the data type of a column.\n#Between: Use between() to filter rows within a range.\n#Contains: Use contains() to filter rows based on substring matching.\n#StartsWith and EndsWith: Use startswith() and endswith() to filter rows based on the beginning or ending of a string.\n#IsNull and IsNotNull: Use isNull() and isNotNull() to filter rows based on null values.\n#Like and RLike: Use like() and rlike() to filter rows based on pattern matching.\n#Substr: Use substr() to extract a substring from a column.\n#When and Otherwise: Use when() and otherwise() to conditionally assign values to a new column.\n#IsIn: Use isin() to filter rows based on a list of values.\n#GetItem: Use getItem() to access elements from an array or map column.\n#GetField: Use getField() to access fields from a struct or map column.\n#DropFields and WithField: Functions for manipulating struct columns (currently commented out).\n#DropFields and WithField: More examples for manipulating struct columns (currently commented out).\n#The code demonstrates how to perform various data manipulation operations on DataFrames in PySpark. It includes column renaming, sorting, data type casting, filtering, substring extraction, conditional column assignment, and accessing elements and fields within complex data structures."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d77d969d-79ed-4d7c-9891-57e756536646","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-column-functions.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
