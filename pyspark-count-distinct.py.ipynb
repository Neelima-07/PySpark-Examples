{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n         .appName('SparkByExamples.com') \\\n         .getOrCreate()\n\ndata = [(\"James\", \"Sales\", 3000),\n    (\"Michael\", \"Sales\", 4600),\n    (\"Robert\", \"Sales\", 4100),\n    (\"Maria\", \"Finance\", 3000),\n    (\"James\", \"Sales\", 3000),\n    (\"Scott\", \"Finance\", 3300),\n    (\"Jen\", \"Finance\", 3900),\n    (\"Jeff\", \"Marketing\", 3000),\n    (\"Kumar\", \"Marketing\", 2000),\n    (\"Saif\", \"Sales\", 4100)\n  ]\ncolumns = [\"Name\",\"Dept\",\"Salary\"]\ndf = spark.createDataFrame(data=data,schema=columns)\ndf.distinct().show()\nprint(\"Distinct Count: \" + str(df.distinct().count()))\n\n# Using countDistrinct()\nfrom pyspark.sql.functions import countDistinct\ndf2=df.select(countDistinct(\"Dept\",\"Salary\"))\ndf2.show()\n\nprint(\"Distinct Count of Department &amp; Salary: \"+ str(df2.collect()[0][0]))\n\ndf.createOrReplaceTempView(\"PERSON\")\nspark.sql(\"select distinct(count(*)) from PERSON\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9795b270-7476-49be-8c51-73db65fa2388","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+---------+------+\n|   Name|     Dept|Salary|\n+-------+---------+------+\n|  James|    Sales|  3000|\n|Michael|    Sales|  4600|\n| Robert|    Sales|  4100|\n|  Maria|  Finance|  3000|\n|  Scott|  Finance|  3300|\n|    Jen|  Finance|  3900|\n|   Jeff|Marketing|  3000|\n|  Kumar|Marketing|  2000|\n|   Saif|    Sales|  4100|\n+-------+---------+------+\n\nDistinct Count: 9\n+----------------------------+\n|count(DISTINCT Dept, Salary)|\n+----------------------------+\n|                           8|\n+----------------------------+\n\nDistinct Count of Department &amp; Salary: 8\n+--------+\n|count(1)|\n+--------+\n|      10|\n+--------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Import the necessary modules: SparkSession from pyspark.sql.\n#Create a SparkSession named 'SparkByExamples.com' using SparkSession.builder.appName('SparkByExamples.com').getOrCreate().\n#Define sample data as a list of tuples, where each tuple represents a row.\n#Define the schema using a list of column names.\n#Create a DataFrame using spark.createDataFrame(data=data, schema=columns).\n#Show the distinct values in the DataFrame using df.distinct().show().\n#Print the count of distinct rows in the DataFrame using df.distinct().count().\n#Use countDistinct() function from pyspark.sql.functions to compute distinct values of specific columns. Create a new DataFrame df2 using df.select(countDistinct(\"Dept\",\"Salary\")) and show its content using df2.show().\n#Print the distinct count of \"Department\" and \"Salary\" columns by extracting the value from the DataFrame using df2.collect()[0][0].\n#Create a temporary view named \"PERSON\" using df.createOrReplaceTempView(\"PERSON\").\n#Execute a SQL query using spark.sql(\"select distinct(count(*)) from PERSON\").show() to compute the distinct count using SQL syntax.\n#The code demonstrates how to calculate distinct values in a DataFrame using both DataFrame operations and SQL queries."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59f24f85-d688-4f6c-a38d-46c2476a82d9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-count-distinct.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
