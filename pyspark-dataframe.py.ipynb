{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, lit\nfrom pyspark.sql.types import StructType, StructField, StringType,IntegerType\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nprint(spark)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2787b6d6-51ea-4d0e-a6bc-3caa9d68a154","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["<pyspark.sql.session.SparkSession object at 0x7fbc705f4400>\n"]}],"execution_count":0},{"cell_type":"code","source":["#It imports the necessary modules from pyspark, pyspark.sql, pyspark.sql.functions, and pyspark.sql.types.\n#It creates a SparkSession object named spark with the specified application name using SparkSession.builder.appName('SparkByExamples.com').getOrCreate(). The getOrCreate() method ensures that if an existing SparkSession with the same name exists, it will be reused, otherwise a new SparkSession will be created.\n#It prints the spark object, which represents the SparkSession.\n#The printed output will provide information about the SparkSession, including its version, configuration, and other details.\n\n#By creating a SparkSession, you can use it to interact with Spark and perform various operations on distributed data using DataFrames and SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"743d52f1-efd1-48bd-a0e4-363d39b54b65","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-dataframe.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
