{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\n\nfrom pyspark.sql.functions import *\n\ndf=spark.createDataFrame([[\"1\"]],[\"id\"])\ndf.select(current_date().alias(\"current_date\"), \\\n      date_format(current_date(),\"yyyy MM dd\").alias(\"yyyy MM dd\"), \\\n      date_format(current_timestamp(),\"MM/dd/yyyy hh:mm\").alias(\"MM/dd/yyyy\"), \\\n      date_format(current_timestamp(),\"yyyy MMM dd\").alias(\"yyyy MMMM dd\"), \\\n      date_format(current_timestamp(),\"yyyy MMMM dd E\").alias(\"yyyy MMMM dd E\") \\\n   ).show()\n\n#SQL\n\nspark.sql(\"select current_date() as current_date, \"+\n      \"date_format(current_timestamp(),'yyyy MM dd') as yyyy_MM_dd, \"+\n      \"date_format(current_timestamp(),'MM/dd/yyyy hh:mm') as MM_dd_yyyy, \"+\n      \"date_format(current_timestamp(),'yyyy MMM dd') as yyyy_MMMM_dd, \"+\n      \"date_format(current_timestamp(),'yyyy MMMM dd E') as yyyy_MMMM_dd_E\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a916e8e2-7c2d-46a9-865c-ba5557589c62","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------+----------+----------------+------------+----------------+\n|current_date|yyyy MM dd|      MM/dd/yyyy|yyyy MMMM dd|  yyyy MMMM dd E|\n+------------+----------+----------------+------------+----------------+\n|  2023-06-19|2023 06 19|06/19/2023 08:25| 2023 Jun 19|2023 June 19 Mon|\n+------------+----------+----------------+------------+----------------+\n\n+------------+----------+----------------+------------+----------------+\n|current_date|yyyy_MM_dd|      MM_dd_yyyy|yyyy_MMMM_dd|  yyyy_MMMM_dd_E|\n+------------+----------+----------------+------------+----------------+\n|  2023-06-19|2023 06 19|06/19/2023 08:25| 2023 Jun 19|2023 June 19 Mon|\n+------------+----------+----------------+------------+----------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#It imports the necessary modules: SparkSession from pyspark.sql and functions (current_date, date_format, current_timestamp) from pyspark.sql.functions.\n#It creates a SparkSession object named spark using SparkSession.builder.appName('SparkByExamples.com').getOrCreate().\n#It creates a DataFrame df with a single row containing the value \"1\" and a column named \"id\".\n#It uses the select method on df to apply different date formatting functions from pyspark.sql.functions to the current date and current timestamp. The functions used are:\n#current_date() returns the current date.\n#date_format() formats a date or timestamp column using a specified pattern.\n#current_timestamp() returns the current timestamp.\n#It shows the result of the select operation, displaying the formatted date values.\n#It uses Spark SQL to execute a SQL query that performs the same date formatting operations as the previous step.\n#It shows the result of the SQL query, displaying the formatted date values.\n#Both the DataFrame API and Spark SQL provide the ability to apply date formatting functions to manipulate and format dates and timestamps according to specified patterns."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e254d33c-6ae6-4a94-ba07-e955f2eab158","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-date-string.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
