{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import explode, flatten\n\n\nspark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()\n\narrayArrayData = [\n  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n]\n\ndf = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\ndf.printSchema()\ndf.show(truncate=False)\n\n\"\"\" \"\"\"\ndf.select(df.name,explode(df.subjects)).show(truncate=False)\n\n\"\"\" creates a single array from an array of arrays. \"\"\"\ndf.select(df.name,flatten(df.subjects)).show(truncate=False)\n\n\"\"\"END\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b28f8981-062f-4295-8d9f-cdb36afca6d6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- subjects: array (nullable = true)\n |    |-- element: array (containsNull = true)\n |    |    |-- element: string (containsNull = true)\n\n+-------+-----------------------------------+\n|name   |subjects                           |\n+-------+-----------------------------------+\n|James  |[[Java, Scala, C++], [Spark, Java]]|\n|Michael|[[Spark, Java, C++], [Spark, Java]]|\n|Robert |[[CSharp, VB], [Spark, Python]]    |\n+-------+-----------------------------------+\n\n+-------+------------------+\n|name   |col               |\n+-------+------------------+\n|James  |[Java, Scala, C++]|\n|James  |[Spark, Java]     |\n|Michael|[Spark, Java, C++]|\n|Michael|[Spark, Java]     |\n|Robert |[CSharp, VB]      |\n|Robert |[Spark, Python]   |\n+-------+------------------+\n\n+-------+-------------------------------+\n|name   |flatten(subjects)              |\n+-------+-------------------------------+\n|James  |[Java, Scala, C++, Spark, Java]|\n|Michael|[Spark, Java, C++, Spark, Java]|\n|Robert |[CSharp, VB, Spark, Python]    |\n+-------+-------------------------------+\n\nOut[1]: 'END'"]}],"execution_count":0},{"cell_type":"code","source":["#It imports the necessary modules: pyspark and SparkSession.\n#It creates a SparkSession object named spark with the configuration appName('pyspark-by-examples').\n#It defines an array of array data arrayArrayData containing tuples with a name and subjects.\n#It creates a DataFrame df by calling spark.createDataFrame() and passing arrayArrayData and the schema as arguments. The schema is defined with two columns: 'name' and 'subjects'. The resulting DataFrame is displayed using df.printSchema() and df.show().\n#It imports the explode and flatten functions from pyspark.sql.functions.\n#It applies the explode function to the 'subjects' column of df by calling df.select() and passing df.name and explode(df.subjects) as arguments. The resulting DataFrame is displayed using df.select(df.name,explode(df.subjects)).show(). This function creates a new row for each element of the array in the 'subjects' column, along with the corresponding 'name' value.\n#It applies the flatten function to the 'subjects' column of df by calling df.select() and passing df.name and flatten(df.subjects) as arguments. The resulting DataFrame is displayed using df.select(df.name,flatten(df.subjects)).show(). This function creates a single array by merging all arrays in the 'subjects' column."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c76f7ef-adc0-4784-aef5-6c687285d71a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-explode-nested-array.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
