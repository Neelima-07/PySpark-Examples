{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,sum,avg,max\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nsimpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n  ]\n\nschema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\ndf = spark.createDataFrame(data=simpleData, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)\n\ndf.groupBy(\"department\").sum(\"salary\").show(truncate=False)\n\ndf.groupBy(\"department\").count().show(truncate=False)\n\n\ndf.groupBy(\"department\",\"state\") \\\n    .sum(\"salary\",\"bonus\") \\\n   .show(truncate=False)\n\ndf.groupBy(\"department\") \\\n    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n         avg(\"salary\").alias(\"avg_salary\"), \\\n         sum(\"bonus\").alias(\"sum_bonus\"), \\\n         max(\"bonus\").alias(\"max_bonus\") \\\n     ) \\\n    .show(truncate=False)\n    \ndf.groupBy(\"department\") \\\n    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n      avg(\"salary\").alias(\"avg_salary\"), \\\n      sum(\"bonus\").alias(\"sum_bonus\"), \\\n      max(\"bonus\").alias(\"max_bonus\")) \\\n    .where(col(\"sum_bonus\") >= 50000) \\\n    .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f451a482-dd93-4174-98b2-051cd4a23f4a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NY   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |CA   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |CA   |80000 |25 |18000|\n|Kumar        |Marketing |NY   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|Sales     |257000     |\n|Finance   |351000     |\n|Marketing |171000     |\n+----------+-----------+\n\n+----------+-----+\n|department|count|\n+----------+-----+\n|Sales     |3    |\n|Finance   |4    |\n|Marketing |2    |\n+----------+-----+\n\n+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|Sales     |NY   |176000     |30000     |\n|Sales     |CA   |81000      |23000     |\n|Finance   |CA   |189000     |47000     |\n|Finance   |NY   |162000     |34000     |\n|Marketing |NY   |91000      |21000     |\n|Marketing |CA   |80000      |18000     |\n+----------+-----+-----------+----------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n|Marketing |171000    |85500.0          |39000    |21000    |\n+----------+----------+-----------------+---------+---------+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|Sales     |257000    |85666.66666666667|53000    |23000    |\n|Finance   |351000    |87750.0          |81000    |24000    |\n+----------+----------+-----------------+---------+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Creating the DataFrame: This section is the same as before, where a DataFrame df is created from a list of tuples with a specified schema.\n\n#Grouping and Summing: This section shows how to group the DataFrame by the 'department' column and calculate the sum of 'salary' for each group using the groupBy and sum functions. The results are displayed using show().\n\n#Grouping and Counting: This section demonstrates how to group the DataFrame by the 'department' column and count the number of occurrences in each group using the groupBy and count functions. The results are displayed using show().\n\n#Grouping and Summing Multiple Columns: This section shows how to group the DataFrame by multiple columns ('department' and 'state') and calculate the sum of 'salary' and 'bonus' for each group using the groupBy and sum functions. The results are displayed using show().\n\n#Grouping, Aggregating, and Alias: This section demonstrates how to group the DataFrame by the 'department' column and calculate multiple aggregations, such as sum, average, and max, on the 'salary' and 'bonus' columns using the groupBy and agg functions. Column aliases are assigned using alias. The results are displayed using show().\n\n#Filtering After Aggregation: This section shows how to perform filtering after the aggregation. It filters the results from the previous section based on the condition that the sum of the 'bonus' column is greater than or equal to 50000 using the where function and displays the filtered results using show().\n\n#These examples provide insights into using PySpark's DataFrame API for grouping, aggregating, and filtering data in various ways."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cefbf034-9434-433e-af73-fcb84235b579","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-groupby.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
