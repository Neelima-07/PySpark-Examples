{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndataDictionary = [\n        ('James',{'hair':'black','eye':'brown'}),\n        ('Michael',{'hair':'brown','eye':None}),\n        ('Robert',{'hair':'red','eye':'black'}),\n        ('Washington',{'hair':'grey','eye':'grey'}),\n        ('Jefferson',{'hair':'brown','eye':''})\n        ]\n\n# Using StructType schema\nfrom pyspark.sql.types import StructField, StructType, StringType, MapType\nschema = StructType([\n    StructField('name', StringType(), True),\n    StructField('properties', MapType(StringType(),StringType()),True)\n])\ndf = spark.createDataFrame(data=dataDictionary, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)\n\ndf3=df.rdd.map(lambda x: \\\n    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n    .toDF([\"name\",\"hair\",\"eye\"])\ndf3.printSchema()\ndf3.show()\n\ndf.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n  .drop(\"properties\") \\\n  .show()\n\ndf.withColumn(\"hair\",df.properties[\"hair\"]) \\\n  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n  .drop(\"properties\") \\\n  .show()\n\nfrom pyspark.sql.functions import explode\ndf.select(df.name,explode(df.properties)).show()\n\nfrom pyspark.sql.functions import map_keys\ndf.select(df.name,map_keys(df.properties)).show()\n\nfrom pyspark.sql.functions import map_values\ndf.select(df.name,map_values(df.properties)).show()\n\n#from pyspark.sql.functions import explode,map_keys\n#keysDF = df.select(explode(map_keys(df.properties))).distinct()\n#keysList = keysDF.rdd.map(lambda x:x[0]).collect()\n#print(keysList)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"76df9b67-1ad6-4664-af0d-235bb284f858","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -> brown, hair -> black}|\n|Michael   |{eye -> null, hair -> brown} |\n|Robert    |{eye -> black, hair -> red}  |\n|Washington|{eye -> grey, hair -> grey}  |\n|Jefferson |{eye -> , hair -> brown}     |\n+----------+-----------------------------+\n\nroot\n |-- name: string (nullable = true)\n |-- hair: string (nullable = true)\n |-- eye: string (nullable = true)\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n+----------+----+-----+\n|      name| key|value|\n+----------+----+-----+\n|     James| eye|brown|\n|     James|hair|black|\n|   Michael| eye| null|\n|   Michael|hair|brown|\n|    Robert| eye|black|\n|    Robert|hair|  red|\n|Washington| eye| grey|\n|Washington|hair| grey|\n| Jefferson| eye|     |\n| Jefferson|hair|brown|\n+----------+----+-----+\n\n+----------+--------------------+\n|      name|map_keys(properties)|\n+----------+--------------------+\n|     James|         [eye, hair]|\n|   Michael|         [eye, hair]|\n|    Robert|         [eye, hair]|\n|Washington|         [eye, hair]|\n| Jefferson|         [eye, hair]|\n+----------+--------------------+\n\n+----------+----------------------+\n|      name|map_values(properties)|\n+----------+----------------------+\n|     James|        [brown, black]|\n|   Michael|         [null, brown]|\n|    Robert|          [black, red]|\n|Washington|          [grey, grey]|\n| Jefferson|             [, brown]|\n+----------+----------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Importing Libraries:\n\n#The necessary library, pyspark.sql.SparkSession, is imported to create a SparkSession and work with DataFrames.\n#Additional functions and types are imported from pyspark.sql.functions and pyspark.sql.types for specific operations.\n#Creating SparkSession:\n\n#spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate() creates a SparkSession with the application name \"SparkByExamples.com\".\n#Creating DataFrame with MapType Column:\n\n#The code defines a list of tuples, dataDictionary, where each tuple contains a name and a properties map.\n#A StructType schema is defined using StructField and MapType to specify the structure of the DataFrame.\n#df = spark.createDataFrame(data=dataDictionary, schema=schema) creates a DataFrame, df, using the provided data and schema.\n#Displaying DataFrame:\n\n#df.printSchema() displays the schema of the DataFrame.\n#df.show(truncate=False) displays the data in the DataFrame.\n#Accessing MapType Column:\n\n#The code demonstrates various operations to access and manipulate the MapType column, properties, in the DataFrame.\n#It shows how to extract specific values from the map using getItem() and create separate columns for them.\n#The DataFrame is modified by dropping the original properties column.\n#Exploding MapType Column:\n\n#The explode() function from pyspark.sql.functions is used to explode the properties map into separate rows with key-value pairs.\n#df.select(df.name, explode(df.properties)).show() displays the exploded DataFrame with the name and exploded properties.\n#Accessing Map Keys and Values:\n\n#The map_keys() and map_values() functions from pyspark.sql.functions are used to extract the keys and values of the properties map, respectively.\n#df.select(df.name, map_keys(df.properties)).show() displays the DataFrame with the name and keys of the properties.\n#df.select(df.name, map_values(df.properties)).show() displays the DataFrame with the name and values of the properties.\n#The code showcases various operations to work with DataFrame columns of MapType, including accessing specific values, exploding the map into separate rows, and extracting keys and values from the map."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69390aa2-b1fb-41f8-8f59-ed5851714064","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-maptype-dataframe-column.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
