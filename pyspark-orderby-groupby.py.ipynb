{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,sum,avg,max\n\nspark = SparkSession.builder \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\nsimpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n    (\"Michael\",\"Sales\",\"NV\",86000,56,20000),\n    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n    (\"Raman\",\"Finance\",\"DE\",99000,40,24000),\n    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n    (\"Jeff\",\"Marketing\",\"NV\",80000,25,18000),\n    (\"Kumar\",\"Marketing\",\"NJ\",91000,50,21000)\n  ]\n\nschema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\ndf = spark.createDataFrame(data=simpleData, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)\n\ndfSort=df.sort(df.state,df.salary).groupBy(df.state).agg(sum(df.salary))\ndfSort.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ca18a58b-8a17-489d-b889-8ae7a1962436","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|James        |Sales     |NY   |90000 |34 |10000|\n|Michael      |Sales     |NV   |86000 |56 |20000|\n|Robert       |Sales     |CA   |81000 |30 |23000|\n|Maria        |Finance   |CA   |90000 |24 |23000|\n|Raman        |Finance   |DE   |99000 |40 |24000|\n|Scott        |Finance   |NY   |83000 |36 |19000|\n|Jen          |Finance   |NY   |79000 |53 |15000|\n|Jeff         |Marketing |NV   |80000 |25 |18000|\n|Kumar        |Marketing |NJ   |91000 |50 |21000|\n+-------------+----------+-----+------+---+-----+\n\n+-----+-----------+\n|state|sum(salary)|\n+-----+-----------+\n|   NY|     252000|\n|   NV|     166000|\n|   CA|     171000|\n|   DE|      99000|\n|   NJ|      91000|\n+-----+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Importing Libraries and Creating SparkSession:\n\n#The necessary libraries, pyspark.sql.SparkSession and pyspark.sql.functions, are imported.\n#spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate() creates a SparkSession with the application name \"SparkByExamples.com\".\n#Creating DataFrame:\n\n#The code defines a list of tuples, simpleData, representing employee data with attributes such as name, department, state, salary, age, and bonus.\n#schema is a list that defines the schema of the DataFrame.\n#df = spark.createDataFrame(data=simpleData, schema=schema) creates a DataFrame, df, using the provided data and schema.\n#Displaying DataFrame:\n\n#df.printSchema() displays the schema of the DataFrame.\n#df.show(truncate=False) displays the data in the DataFrame.\n#Sorting, Grouping, and Aggregation:\n\n#df.sort(df.state, df.salary) sorts the DataFrame by the \"state\" and \"salary\" columns.\n#groupBy(df.state) groups the sorted DataFrame by the \"state\" column.\n#agg(sum(df.salary)) performs aggregation by calculating the sum of the \"salary\" column within each group.\n#dfSort.show() displays the sorted and aggregated DataFrame.\n#The code demonstrates how to sort a DataFrame by multiple columns, group the data based on a specific column, and perform aggregation operations using the sort(), groupBy(), and agg() functions in PySpark. The resulting DataFrame (dfSort) displays the sum of salaries for each unique state."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b54b8311-ca56-4b17-bbc4-847b34f688a8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-orderby-groupby.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
