{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd=spark.sparkContext.parallelize([1,2,3,4,5])\n\nrddCollect = rdd.collect()\nprint(\"Number of Partitions: \"+str(rdd.getNumPartitions()))\nprint(\"Action: First element: \"+str(rdd.first()))\nprint(rddCollect)\n\nemptyRDD = spark.sparkContext.emptyRDD()\nemptyRDD2 = rdd=spark.sparkContext.parallelize([])\n\nprint(\"\"+str(emptyRDD2.isEmpty()))\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9ce9224b-0ec5-4111-a71e-e32f34fb486a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Number of Partitions: 8\nAction: First element: 1\n[1, 2, 3, 4, 5]\nTrue\n"]}],"execution_count":0},{"cell_type":"code","source":["#Importing Libraries: The code begins by importing the necessary libraries, pyspark and SparkSession from pyspark.sql.\n\n#Creating Spark Session: A Spark session is created using SparkSession.builder.appName('SparkByExamples.com').getOrCreate(). This creates a Spark session with the specified application name or retrieves an existing one.\n\n#Creating RDD: An RDD (Resilient Distributed Dataset) is created using spark.sparkContext.parallelize([1, 2, 3, 4, 5]). The list [1, 2, 3, 4, 5] is converted into an RDD.\n\n#Performing Actions and Transformations: Several actions and transformations are performed on the RDD:\n\n#rdd.getNumPartitions() returns the number of partitions in the RDD.\n#rdd.first() returns the first element of the RDD.\n#rdd.collect() collects all the elements of the RDD into a list.\n#Printing Results: The results of the actions and transformations are printed using print() statements.\n\n#Creating Empty RDD: An empty RDD is created using spark.sparkContext.emptyRDD(). This creates an RDD with no elements.\n\n#Checking if Empty RDD: The isEmpty() method is used to check if the emptyRDD2 is empty. The result is printed using print().\n\n#Overall, this code demonstrates basic operations in PySpark, including creating an RDD, performing actions and transformations, and creating an empty RDD."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b2eb4423-406c-40e4-b725-7f227dd3d25a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-parallelize.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
