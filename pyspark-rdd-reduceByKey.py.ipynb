{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata = [('Project', 1),\n('Gutenberg’s', 1),\n('Alice’s', 1),\n('Adventures', 1),\n('in', 1),\n('Wonderland', 1),\n('Project', 1),\n('Gutenberg’s', 1),\n('Adventures', 1),\n('in', 1),\n('Wonderland', 1),\n('Project', 1),\n('Gutenberg’s', 1)]\n\nrdd=spark.sparkContext.parallelize(data)\n\nrdd2=rdd.reduceByKey(lambda a,b: a+b)\nfor element in rdd2.collect():\n    print(element)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"310a43e5-f958-4bce-b8db-ef3e2f3ecc6d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["('Gutenberg’s', 3)\n('Adventures', 2)\n('Wonderland', 2)\n('Alice’s', 1)\n('in', 2)\n('Project', 3)\n"]}],"execution_count":0},{"cell_type":"code","source":["#Importing SparkSession: The SparkSession class is imported from the pyspark.sql module.\n\n#Creating a SparkSession: The SparkSession is created using the SparkSession.builder method with the application name set to 'SparkByExamples.com'. If a SparkSession already exists, it returns that instance; otherwise, it creates a new one.\n\n#Defining data: The data variable is defined as a list of tuples. Each tuple consists of a word and a count.\n\n#Creating an RDD: An RDD named rdd is created using spark.sparkContext.parallelize(data). The RDD is parallelized from the data list.\n\n#Reducing by key: The RDD elements are reduced by key using rdd.reduceByKey(lambda a, b: a + b). This operation performs a reduction on the values associated with each key by applying the provided lambda function (in this case, a simple addition).\n\n#Collecting and printing RDD elements: The reduced RDD elements are collected using rdd2.collect(). It returns a list of key-value tuples, where the key is the word and the value is the sum of counts. Each tuple is printed.\n\n#The code essentially performs a word count operation, where it counts the occurrences of each word in the RDD and prints the results."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"49c23bb0-bfcb-4a36-a237-46a674686e5c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd-reduceByKey.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
