{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n  ]\n\ncolumns = [\"firstname\",\"lastname\",\"country\",\"state\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf.show(truncate=False)\n\n\ndf.select(\"firstname\",\"lastname\").show()\n\n#Using Dataframe object name\ndf.select(df.firstname,df.lastname).show()\ndf.select(df[\"firstname\"],df[\"lastname\"]).show()\n\n# Using col function\nfrom pyspark.sql.functions import col\ndf.select(col(\"firstname\").alias(\"fname\"),col(\"lastname\")).show()\n\n# Show all columns\ndf.select(\"*\").show()\ndf.select([col for col in df.columns]).show()\ndf.select(*columns).show()\n\ndf.select(df.columns[:3]).show(3)\ndf.select(df.columns[2:4]).show(3)\n\ndf.select(df.colRegex(\"`^.*name*`\")).show()\n\ndata = [\n        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n        ]\n\nfrom pyspark.sql.types import StructType,StructField, StringType        \nschema = StructType([\n    StructField('name', StructType([\n         StructField('firstname', StringType(), True),\n         StructField('middlename', StringType(), True),\n         StructField('lastname', StringType(), True)\n         ])),\n     StructField('state', StringType(), True),\n     StructField('gender', StringType(), True)\n     ])\n\n\ndf2 = spark.createDataFrame(data = data, schema = schema)\ndf2.printSchema()\ndf2.show(truncate=False) # shows all columns\ndf2.select(\"name\").show(truncate=False)\ndf2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)\ndf2.select(\"name.*\").show(truncate=False)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d18e6bcb-f327-48ae-a9b7-6d09293bf0a3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|James    |Smith   |USA    |CA   |\n|Michael  |Rose    |USA    |NY   |\n|Robert   |Williams|USA    |CA   |\n|Maria    |Jones   |USA    |FL   |\n+---------+--------+-------+-----+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+-------+--------+\n|  fname|lastname|\n+-------+--------+\n|  James|   Smith|\n|Michael|    Rose|\n| Robert|Williams|\n|  Maria|   Jones|\n+-------+--------+\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n+---------+--------+-------+\n|firstname|lastname|country|\n+---------+--------+-------+\n|    James|   Smith|    USA|\n|  Michael|    Rose|    USA|\n|   Robert|Williams|    USA|\n+---------+--------+-------+\nonly showing top 3 rows\n\n+-------+-----+\n|country|state|\n+-------+-----+\n|    USA|   CA|\n|    USA|   NY|\n|    USA|   CA|\n+-------+-----+\nonly showing top 3 rows\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+-----+------+\n|name                  |state|gender|\n+----------------------+-----+------+\n|{James, null, Smith}  |OH   |M     |\n|{Anna, Rose, }        |NY   |F     |\n|{Julia, , Williams}   |OH   |F     |\n|{Maria, Anne, Jones}  |NY   |M     |\n|{Jen, Mary, Brown}    |NY   |M     |\n|{Mike, Mary, Williams}|OH   |M     |\n+----------------------+-----+------+\n\n+----------------------+\n|name                  |\n+----------------------+\n|{James, null, Smith}  |\n|{Anna, Rose, }        |\n|{Julia, , Williams}   |\n|{Maria, Anne, Jones}  |\n|{Jen, Mary, Brown}    |\n|{Mike, Mary, Williams}|\n+----------------------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|James    |Smith   |\n|Anna     |        |\n|Julia    |Williams|\n|Maria    |Jones   |\n|Jen      |Brown   |\n|Mike     |Williams|\n+---------+--------+\n\n+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|James    |null      |Smith   |\n|Anna     |Rose      |        |\n|Julia    |          |Williams|\n|Maria    |Anne      |Jones   |\n|Jen      |Mary      |Brown   |\n|Mike     |Mary      |Williams|\n+---------+----------+--------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code starts by importing the necessary modules: pyspark and SparkSession from pyspark.sql. These modules are required for working with Spark DataFrames.\n\n#Next, a SparkSession is created using the SparkSession.builder API. The appName parameter sets the name of the Spark application, and getOrCreate() either retrieves an existing SparkSession or creates a new one if none exists.\n\n#The code defines a sample data as a list of tuples, where each tuple represents a row in the DataFrame. The data list contains four rows with four columns: firstname, lastname, country, and state.\n\n#The columns list contains the column names for the DataFrame.\n\n#The spark.createDataFrame() method is used to create a DataFrame from the data and columns. The data parameter is set to the input data, and the schema parameter is set to the list of columns.\n\n#The df.show(truncate=False) statement is used to display the DataFrame. show() is a method in Spark DataFrame that prints the contents of the DataFrame to the console. The truncate=False parameter ensures that the output does not truncate the displayed data.\n\n#Various operations on the DataFrame are demonstrated:\n\n#df.select(\"firstname\", \"lastname\").show() selects the \"firstname\" and \"lastname\" columns and displays them.\n#df.select(df.firstname, df.lastname).show() selects the columns using DataFrame object name and displays them.\n#df.select(df[\"firstname\"], df[\"lastname\"]).show() selects the columns using indexing syntax and displays them.\n#df.select(col(\"firstname\").alias(\"fname\"), col(\"lastname\")).show() uses the col() function from pyspark.sql.functions to select columns and rename the \"firstname\" column to \"fname\".\n#df.select(\"*\").show() selects all columns and displays them.\n#df.select([col for col in df.columns]).show() selects all columns using a list comprehension and displays them.\n#df.select(*columns).show() selects all columns using the * operator and displays them.\n#df.select(df.columns[:3]).show(3) selects the first three columns using column indexing and displays the first three rows.\n#df.select(df.columns[2:4]).show(3) selects columns using column indexing and displays the first three rows.\n#df.select(df.colRegex(\"^.name\")).show() selects columns matching a regular expression pattern and displays them.\n#The code then defines a more complex schema using the StructType and StructField classes from pyspark.sql.types. This schema represents a nested structure where the \"name\" field contains a structure with \"firstname\", \"middlename\", and \"lastname\" fields.\n\n#Another DataFrame df2 is created using the more complex schema and a list of data tuples. The spark.createDataFrame() method is used with the data and schema parameters.\n\n#The df2.printSchema() statement prints the schema of the DataFrame, showing the structure of nested fields.\n\n#The df2.show(truncate=False) statement displays the contents of the DataFrame.\n\n#Various select() operations are performed on df2 to demonstrate selecting columns and nested fields. For example, df2.select(\"name\") selects the \"name\" column, df2.select(\"name.firstname\", \"name.lastname\") selects the \"firstname\" and \"lastname\" columns within the \"name\" field, and `df2.select\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7d95f8a-cfb6-49a1-ba57-e0f8ad72d5ee","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-select-columns.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
