{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nsimpleData = [(\"James\",34),(\"Ann\",34),\n    (\"Michael\",33),(\"Scott\",53),\n    (\"Robert\",37),(\"Chad\",27)\n  ]\n\ncolumns = [\"firstname\",\"age\",]\ndf = spark.createDataFrame(data = simpleData, schema = columns)\n\n\ndf.show()\n#Returns the first ``num`` rows as a :class:`list` of :class:`Row`.\n# Internally calls limit and collect\n#Action, Return Array[T]\nprint(df.take(2))\n\n#Returns the last ``num`` rows as a :class:`list` of :class:`Row`.\n#Running tail requires moving data into the application's driver process, and doing so with\n#a very large ``num`` can crash the driver process with OutOfMemoryError.\n#Return Array[T]\nprint(df.tail(2))\n\n\n\"\"\"Returns the first ``n`` rows.\n\n.. note:: This method should only be used if the resulting array is expected\n    to be small, as all the data is loaded into the driver's memory.\n\n:param n: int, default 1. Number of rows to return.\n:return: If n is greater than 1, return a list of :class:`Row`.\n    If n is 1, return a single Row.\"\"\"\n#Return Array[T]\nprint(df.head(2))\n\n\n#Returns the first row, same as df.head(1)\nprint(df.first())\n\n#Returns all the records as a list of :class:`Row`.\n#Action, Return Array[T]\nprint(df.collect())\n#\"Limits the result count to the number specified.\n#Returns a new Dataset by taking the first n rows.\npandasDF=df.limit(3).toPandas()\nprint(pandasDF)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"015f40e9-4abc-4fa0-825f-ca3011bae572","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+---+\n|firstname|age|\n+---------+---+\n|    James| 34|\n|      Ann| 34|\n|  Michael| 33|\n|    Scott| 53|\n|   Robert| 37|\n|     Chad| 27|\n+---------+---+\n\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34)]\n[Row(firstname='Robert', age=37), Row(firstname='Chad', age=27)]\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34)]\nRow(firstname='James', age=34)\n[Row(firstname='James', age=34), Row(firstname='Ann', age=34), Row(firstname='Michael', age=33), Row(firstname='Scott', age=53), Row(firstname='Robert', age=37), Row(firstname='Chad', age=27)]\n  firstname  age\n0     James   34\n1       Ann   34\n2   Michael   33\n"]}],"execution_count":0},{"cell_type":"code","source":["#take(n): Returns the first n rows of the DataFrame as a list of Rows. It internally calls the limit() and collect() methods.\n\n#tail(n): Returns the last n rows of the DataFrame as a list of Rows. Retrieving the tail requires moving data into the driver's process, and retrieving a large number of rows can potentially cause memory issues.\n\n#head(n): Returns the first n rows of the DataFrame. If n is greater than 1, it returns a list of Rows. If n is 1, it returns a single Row.\n\n#first(): Returns the first row of the DataFrame as a Row object.\n\n#collect(): Returns all the rows of the DataFrame as a list of Rows. This method should be used cautiously as it loads all the data into the driver's memory, and it may cause memory issues if the DataFrame is large.\n\n#limit(n): Limits the result count to the specified number n and returns a new DataFrame with the first n rows.\n\n#toPandas(): Converts the DataFrame to a Pandas DataFrame. This method can be used to retrieve all the rows of the DataFrame as a Pandas DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a7101ffb-083d-4168-8953-9bbf1aee07fa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-show-top-n-rows.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
