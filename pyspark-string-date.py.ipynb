{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\n\nfrom pyspark.sql.functions import *\n\ndf=spark.createDataFrame([[\"02-03-2013\"],[\"05-06-2023\"]],[\"input\"])\ndf.select(col(\"input\"),to_date(col(\"input\"),\"MM-dd-yyyy\").alias(\"date\")) \\\n  .show()\n\n#SQL\nspark.sql(\"select to_date('02-03-2013','MM-dd-yyyy') date\").show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"77a6b9a4-6be1-4607-86bd-807ba68da65e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----------+\n|     input|      date|\n+----------+----------+\n|02-03-2013|2013-02-03|\n|05-06-2023|2023-05-06|\n+----------+----------+\n\n+----------+\n|      date|\n+----------+\n|2013-02-03|\n+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code starts by importing the necessary modules: SparkSession from pyspark.sql and all the functions from pyspark.sql.functions. These modules are required for creating a SparkSession and performing date-related operations.\n\n#A SparkSession is created using the SparkSession.builder API. The appName parameter sets the name of the Spark application. If an existing SparkSession with the same name exists, it will be retrieved; otherwise, a new SparkSession will be created.\n\n#Sample data is created as a DataFrame with a single column named \"input\". It contains two date strings in the format \"MM-dd-yyyy\".\n\n#The select() function is used to select the \"input\" column and apply the to_date() function on it. The to_date() function converts the date string to a date object based on the specified date format (\"MM-dd-yyyy\"). The alias() function is used to rename the resulting column as \"date\".\n\n#The resulting DataFrame with the \"input\" and \"date\" columns is displayed using the show() function.\n\n#The code also demonstrates an alternative way to achieve the same result using Spark SQL. It executes a SQL query that applies the to_date() function on a given date string and aliases the resulting column as \"date\". The resulting DataFrame is displayed using the show() function."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"61da1e57-67a6-480b-b1a0-b0b030fdd268","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-string-date.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
