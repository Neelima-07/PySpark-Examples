{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\nfrom pyspark.sql.functions import *\n\ndf=spark.createDataFrame(\n        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\ndf.printSchema()\n\n#Timestamp String to DateType\ndf.withColumn(\"timestamp\",to_timestamp(\"input_timestamp\")) \\\n  .show(truncate=False)\n  \n# Using Cast to convert TimestampType to DateType\ndf.withColumn('timestamp', \\\n         to_timestamp('input_timestamp').cast('string')) \\\n  .show(truncate=False)\n  \n\ndf.select(to_timestamp(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show(truncate=False)\n  \n\n#SQL string to TimestampType\nspark.sql(\"select to_timestamp('2019-06-24 12:01:19.000') as timestamp\")\n#SQL CAST timestamp string to TimestampType\nspark.sql(\"select timestamp('2019-06-24 12:01:19.000') as timestamp\")\n#SQL Custom string to TimestampType\nspark.sql(\"select to_timestamp('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as timestamp\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9138446f-b112-476c-8802-4d0ab908f4e3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+-------------------+\n|id |input_timestamp        |timestamp          |\n+---+-----------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+\n\n+---+-----------------------+-------------------+\n|id |input_timestamp        |timestamp          |\n+---+-----------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+\n\n+---------------------------------------------------------------+\n|to_timestamp(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+---------------------------------------------------------------+\n|2019-06-24 12:01:19                                            |\n+---------------------------------------------------------------+\n\nOut[1]: DataFrame[timestamp: timestamp]"]}],"execution_count":0},{"cell_type":"code","source":["#The code starts by importing the necessary modules: SparkSession from pyspark.sql and all the functions from pyspark.sql.functions. These modules are required for creating a SparkSession and performing timestamp conversions.\n\n#A SparkSession is created using the SparkSession.builder API. The appName parameter sets the name of the Spark application. If an existing SparkSession with the same name exists, it will be retrieved; otherwise, a new SparkSession will be created.\n\n#A DataFrame is created with a single row containing two columns: \"id\" and \"input_timestamp\". The \"input_timestamp\" column contains a timestamp string in the format \"yyyy-MM-dd HH:mm:ss.SSS\".\n\n#The schema of the DataFrame is printed using the printSchema() function.\n\n#The to_timestamp() function is used to convert the \"input_timestamp\" column to a TimestampType. The resulting column is named \"timestamp\". The DataFrame is displayed using the show() function.\n\n#Another way to convert the \"input_timestamp\" column to a TimestampType is by using the cast() function. First, the to_timestamp() function is applied to convert the string to a TimestampType, and then the cast() function is used to convert it back to a string. The resulting column is named \"timestamp\". The DataFrame is displayed using the show() function.\n\n#The to_timestamp() function is used in conjunction with the lit() function to convert a hardcoded timestamp string (\"06-24-2019 12:01:19.000\") to a TimestampType. The resulting column is named \"timestamp\". The DataFrame is displayed using the show() function.\n\n#The code also demonstrates the same timestamp conversions using Spark SQL queries. Three separate queries are executed: one using the to_timestamp() function with a hardcoded timestamp string, one using the timestamp() function with a hardcoded timestamp string, and one using the to_timestamp() function with a custom timestamp string format (\"MM-dd-yyyy HH:mm:ss.SSSS\"). These queries return a DataFrame with a single column named \"timestamp\".\n\n#These code snippets showcase different methods to convert timestamp strings to TimestampType in PySpark, providing flexibility in handling timestamp data within Spark DataFrames.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"34eb4da1-796a-4bf7-9907-5f0b5f0de4f8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-string-timestamp.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
