{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,MapType\nfrom pyspark.sql.functions import col,struct,when\n\nspark = SparkSession.builder.master(\"local[1]\") \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ndata = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n  ]\n\nschema = StructType([ \n    StructField(\"firstname\",StringType(),True), \n    StructField(\"middlename\",StringType(),True), \n    StructField(\"lastname\",StringType(),True), \n    StructField(\"id\", StringType(), True), \n    StructField(\"gender\", StringType(), True), \n    StructField(\"salary\", IntegerType(), True) \n  ])\n \ndf = spark.createDataFrame(data=data,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)\n\nstructureData = [\n    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n  ]\nstructureSchema = StructType([\n        StructField('name', StructType([\n             StructField('firstname', StringType(), True),\n             StructField('middlename', StringType(), True),\n             StructField('lastname', StringType(), True)\n             ])),\n         StructField('id', StringType(), True),\n         StructField('gender', StringType(), True),\n         StructField('salary', IntegerType(), True)\n         ])\n\ndf2 = spark.createDataFrame(data=structureData,schema=structureSchema)\ndf2.printSchema()\ndf2.show(truncate=False)\n\n\nupdatedDF = df2.withColumn(\"OtherInfo\", \n    struct(col(\"id\").alias(\"identifier\"),\n    col(\"gender\").alias(\"gender\"),\n    col(\"salary\").alias(\"salary\"),\n    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n      .otherwise(\"High\").alias(\"Salary_Grade\")\n  )).drop(\"id\",\"gender\",\"salary\")\n\nupdatedDF.printSchema()\nupdatedDF.show(truncate=False)\n\n\n\"\"\" Array & Map\"\"\"\n\n\narrayStructureSchema = StructType([\n    StructField('name', StructType([\n       StructField('firstname', StringType(), True),\n       StructField('middlename', StringType(), True),\n       StructField('lastname', StringType(), True)\n       ])),\n       StructField('hobbies', ArrayType(StringType()), True),\n       StructField('properties', MapType(StringType(),StringType()), True)\n    ])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e64d7d99-501b-4e27-8ae9-d76e42c1b6fa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+--------------------+-----+------+------+\n|name                |id   |gender|salary|\n+--------------------+-----+------+------+\n|{James, , Smith}    |36636|M     |3100  |\n|{Michael, Rose, }   |40288|M     |4300  |\n|{Robert, , Williams}|42114|M     |1400  |\n|{Maria, Anne, Jones}|39192|F     |5500  |\n|{Jen, Mary, Brown}  |     |F     |-1    |\n+--------------------+-----+------+------+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- OtherInfo: struct (nullable = false)\n |    |-- identifier: string (nullable = true)\n |    |-- gender: string (nullable = true)\n |    |-- salary: integer (nullable = true)\n |    |-- Salary_Grade: string (nullable = false)\n\n+--------------------+------------------------+\n|name                |OtherInfo               |\n+--------------------+------------------------+\n|{James, , Smith}    |{36636, M, 3100, Medium}|\n|{Michael, Rose, }   |{40288, M, 4300, High}  |\n|{Robert, , Williams}|{42114, M, 1400, Low}   |\n|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n+--------------------+------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code imports necessary modules, including pyspark, SparkSession from pyspark.sql, and various data types and functions.\n\n#A SparkSession is created with the application name set to 'SparkByExamples.com'.\n\n#Two data examples are defined, each representing rows of a DataFrame. The first example uses simple data types, while the second example demonstrates nested struct types.\n\n#The schemas for both examples are defined using the StructType class, specifying the structure and data types of the DataFrame columns.\n\n#DataFrames are created using the spark.createDataFrame() method, passing the data and schema as arguments.\n\n#The schemas of the DataFrames are printed using the printSchema() method.\n\n#The content of the DataFrames is displayed using the show() method.\n\n#The second DataFrame (df2) is updated by creating a new column called \"OtherInfo\" using the withColumn() method. The new column is created by combining existing columns and using conditional logic (when) to determine the \"Salary_Grade\" based on the \"salary\" column. The original columns \"id\", \"gender\", and \"salary\" are dropped using the drop() method.\n\n#The updated DataFrame's schema and content are printed.\n\n#Lastly, a new schema (arrayStructureSchema) is defined with nested struct, array, and map types."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2618218d-c966-4d92-ac17-aca15c12aca7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-structtype.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
