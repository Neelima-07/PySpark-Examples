{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\ndf=spark.createDataFrame(\n        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\ndf.printSchema()\n\n\nfrom pyspark.sql.functions import *\n\n# Using Cast to convert Timestamp String to DateType\ndf.withColumn('date_type', col('input_timestamp').cast('date')) \\\n       .show(truncate=False)\n\n# Using Cast to convert TimestampType to DateType\ndf.withColumn('date_type', to_timestamp('input_timestamp').cast('date')) \\\n  .show(truncate=False)\n\ndf.select(to_date(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show()\n  \n#Timestamp String to DateType\ndf.withColumn(\"date_type\",to_date(\"input_timestamp\")) \\\n  .show(truncate=False)\n\n#Timestamp Type to DateType\ndf.withColumn(\"date_type\",to_date(current_timestamp())) \\\n  .show(truncate=False) \n\ndf.withColumn(\"ts\",to_timestamp(col(\"input_timestamp\"))) \\\n  .withColumn(\"datetype\",to_date(col(\"ts\"))) \\\n  .show(truncate=False)\n    \n#SQL TimestampType to DateType\nspark.sql(\"select to_date(current_timestamp) as date_type\")\n#SQL CAST TimestampType to DateType\nspark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\")\n#SQL CAST timestamp string to DateType\nspark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Timestamp String (default format) to DateType\nspark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Custom Timeformat to DateType\nspark.sql(\"select to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type\")\n\n     "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"25144c30-d4bb-46bb-ab08-19722742de73","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+----------------------------------------------------------+\n|to_date(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+----------------------------------------------------------+\n|                                                2019-06-24|\n+----------------------------------------------------------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2023-06-21|\n+---+-----------------------+----------+\n\n+---+-----------------------+-------------------+----------+\n|id |input_timestamp        |ts                 |datetype  |\n+---+-----------------------+-------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24|\n+---+-----------------------+-------------------+----------+\n\nOut[1]: DataFrame[date_type: date]"]}],"execution_count":0},{"cell_type":"code","source":["#The code imports necessary modules, including SparkSession from pyspark.sql and various functions related to timestamp manipulation.\n\n#A SparkSession is created with the application name set to 'SparkByExamples.com'.\n\n#A DataFrame df is created with a single row containing an id and input_timestamp column.\n\n#Operations on df:\n\n#The input_timestamp column is cast to a date type using the cast() function and assigned to a new column date_type.\n#The input_timestamp column is cast to a timestamp type using the to_timestamp() function and then cast to a date type using the cast() function and assigned to a new column date_type.\n#The input_timestamp column is converted to a date type using the to_date() function and assigned to a new column date_type.\n#The current timestamp is converted to a date type using the to_date() function and assigned to a new column date_type.\n#The input_timestamp column is first converted to a timestamp type using the to_timestamp() function and then converted to a date type using the to_date() function. The resulting DataFrame includes the ts and datetype columns.\n#The DataFrames and calculated columns are displayed using the show() method.\n\n#SQL operations:\n\n#The code uses Spark SQL to perform similar conversions from timestamp to date types using various functions like to_date(), date(), and to_timestamp(). The resulting date is assigned to the date_type column.\n#Overall, this code showcases different ways to convert timestamps to date types in PySpark. It demonstrates how to use functions like cast(), to_timestamp(), to_date(), and SQL expressions to achieve the desired conversions.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f38d65a-e435-4c3c-ad2a-4617e673f03e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-timestamp-date.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
