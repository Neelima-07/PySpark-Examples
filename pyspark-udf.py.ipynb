{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import StringType\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ncolumns = [\"Seqno\",\"Name\"]\ndata = [(\"1\", \"john jones\"),\n    (\"2\", \"tracey smith\"),\n    (\"3\", \"amy sanders\")]\n\ndf = spark.createDataFrame(data=data,schema=columns)\n\ndf.show(truncate=False)\n\ndef convertCase(str):\n    resStr=\"\"\n    arr = str.split(\" \")\n    for x in arr:\n       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n    return resStr \n\n\"\"\" Converting function to UDF \"\"\"\nconvertUDF = udf(lambda z: convertCase(z))\n\ndf.select(col(\"Seqno\"), \\\n    convertUDF(col(\"Name\")).alias(\"Name\") ) \\\n.show(truncate=False)\n\n\n@udf(returnType=StringType()) \ndef upperCase(str):\n    return str.upper()\n\nupperCaseUDF = udf(lambda z:upperCase(z),StringType())    \n\ndf.withColumn(\"Cureated Name\", upperCase(col(\"Name\"))) \\\n.show(truncate=False)\n\n\"\"\" Using UDF on SQL \"\"\"\nspark.udf.register(\"convertUDF\", convertCase,StringType())\ndf.createOrReplaceTempView(\"NAME_TABLE\")\nspark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE\") \\\n     .show(truncate=False)\n     \nspark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \\\n          \"where Name is not null and convertUDF(Name) like '%John%'\") \\\n     .show(truncate=False)  \n     \n\"\"\" null check \"\"\"\n\ncolumns = [\"Seqno\",\"Name\"]\ndata = [(\"1\", \"john jones\"),\n    (\"2\", \"tracey smith\"),\n    (\"3\", \"amy sanders\"),\n    ('4',None)]\n\ndf2 = spark.createDataFrame(data=data,schema=columns)\ndf2.show(truncate=False)\ndf2.createOrReplaceTempView(\"NAME_TABLE2\")\n    \nspark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())\n\nspark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n     .show(truncate=False)\n\nspark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n     .show(truncate=False)  \n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"23d0dda6-906f-4db9-94c9-8a39b5a55999","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----+------------+\n|Seqno|Name        |\n+-----+------------+\n|1    |john jones  |\n|2    |tracey smith|\n|3    |amy sanders |\n+-----+------------+\n\n+-----+-------------+\n|Seqno|Name         |\n+-----+-------------+\n|1    |John Jones   |\n|2    |Tracey Smith |\n|3    |Amy Sanders  |\n+-----+-------------+\n\n+-----+------------+-------------+\n|Seqno|Name        |Cureated Name|\n+-----+------------+-------------+\n|1    |john jones  |JOHN JONES   |\n|2    |tracey smith|TRACEY SMITH |\n|3    |amy sanders |AMY SANDERS  |\n+-----+------------+-------------+\n\n+-----+-------------+\n|Seqno|Name         |\n+-----+-------------+\n|1    |John Jones   |\n|2    |Tracey Smith |\n|3    |Amy Sanders  |\n+-----+-------------+\n\n+-----+-----------+\n|Seqno|Name       |\n+-----+-----------+\n|1    |John Jones |\n+-----+-----------+\n\n+-----+------------+\n|Seqno|Name        |\n+-----+------------+\n|1    |john jones  |\n|2    |tracey smith|\n|3    |amy sanders |\n|4    |null        |\n+-----+------------+\n\n+------------------+\n|_nullsafeUDF(Name)|\n+------------------+\n|John Jones        |\n|Tracey Smith      |\n|Amy Sanders       |\n|                  |\n+------------------+\n\n+-----+-----------+\n|Seqno|Name       |\n+-----+-----------+\n|1    |John Jones |\n+-----+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code imports necessary modules, including SparkSession and functions like col and udf from pyspark.sql, as well as the StringType data type.\n\n#A SparkSession is created with the application name set to 'SparkByExamples.com'.\n\n#Data is created as a list of tuples representing individuals' information.\n\n#A DataFrame df is created using the given data and column names.\n\n#The df DataFrame is displayed using the show() method.\n\n#A function named convertCase is defined to convert the case of a string.\n\n#The convertUDF is created using the udf() function and the convertCase function.\n\n#The df DataFrame is selected with the \"Seqno\" column and the transformed \"Name\" column using the convertUDF and displayed.\n\n#Another UDF named upperCase is defined to convert a string to uppercase.\n\n#The upperCaseUDF is created using the udf() function and the upperCase function.\n\n#The df DataFrame is transformed by adding a new column \"Cureated Name\" with uppercase values using the upperCaseUDF and displayed.\n\n#The convertCase function is registered as a UDF named \"convertUDF\" using spark.udf.register().\n\n#The df DataFrame is temporarily registered as \"NAME_TABLE\" using createOrReplaceTempView().\n\n#A SQL query is executed using spark.sql() to select the \"Seqno\" column and apply the UDF \"convertUDF\" to the \"Name\" column.\n\n#Another SQL query is executed to filter the names containing \"John\" using the UDF \"convertUDF\".\n\n#Another DataFrame df2 is created with an additional row containing None for the \"Name\" column.\n\n#The df2 DataFrame is displayed.\n\n#The df2 DataFrame is temporarily registered as \"NAME_TABLE2\".\n\n#A lambda function is defined as a UDF named \"_nullsafeUDF\" to handle null values in the \"convertCase\" function.\n\n#The \"_nullsafeUDF\" is registered using spark.udf.register().\n\n#A SQL query is executed to apply the \"_nullsafeUDF\" to the \"Name\" column of the \"NAME_TABLE2\", handling null values.\n\n#Another SQL query is executed to filter the names containing \"John\" while handling null values.\n\n#Overall, this code demonstrates the creation and usage of UDFs in PySpark to perform custom transformations on DataFrame columns and handle null values.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8525af06-deb4-4d72-838c-3e2fd4d07935","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-udf.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
