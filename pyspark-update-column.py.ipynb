{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata = [('James','Smith','M',3000),('Anna','Rose','F',4100),\n  ('Robert','Williams','NA',6200),(None,'Rob','F',6200)\n  \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()\n\ndf2=df.withColumn(\"salary\", df.salary*3)\ndf2.show()\n\nfrom pyspark.sql.functions import when\ndf3 = df.withColumn(\"gender\", when(df.gender == \"M\",\"Male\") \\\n      .when(df.gender == \"F\",\"Female\") \\\n      .otherwise(df.gender))\ndf3.show()\n\ndf4=df.withColumn(\"salary\",df.salary.cast(\"String\"))\ndf4.printSchema()\n\ndf.createOrReplaceTempView(\"PER\")\ndf5=spark.sql(\"select firstname,gender,salary*3 as salary from PER\")\ndf5.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f4c1ee5f-0101-4676-8bca-98413c3a92ae","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|  3000|\n|     Anna|    Rose|     F|  4100|\n|   Robert|Williams|    NA|  6200|\n|     null|     Rob|     F|  6200|\n+---------+--------+------+------+\n\n+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|  9000|\n|     Anna|    Rose|     F| 12300|\n|   Robert|Williams|    NA| 18600|\n|     null|     Rob|     F| 18600|\n+---------+--------+------+------+\n\n+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|  Male|  3000|\n|     Anna|    Rose|Female|  4100|\n|   Robert|Williams|    NA|  6200|\n|     null|     Rob|Female|  6200|\n+---------+--------+------+------+\n\nroot\n |-- firstname: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: string (nullable = true)\n\n+---------+------+------+\n|firstname|gender|salary|\n+---------+------+------+\n|    James|     M|  9000|\n|     Anna|     F| 12300|\n|   Robert|    NA| 18600|\n|     null|     F| 18600|\n+---------+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code imports the necessary modules, including SparkSession from pyspark.sql.\n\n#A SparkSession is created with the application name set to 'SparkByExamples.com'.\n\n#The data list contains tuples representing input data for the DataFrame.\n\n#The columns list defines the column names for the DataFrame.\n\n#The DataFrame df is created using spark.createDataFrame() by passing the input data and schema.\n\n#The contents of df are displayed using show().\n\n#The DataFrame df2 is created by multiplying the \"salary\" column in df by 3 using withColumn(). The resulting DataFrame is displayed using show().\n\n#The when() function from pyspark.sql.functions is used to conditionally update the \"gender\" column in df. If \"M\" is encountered, it is replaced with \"Male\", if \"F\" is encountered, it is replaced with \"Female\", and for other values, the original value is retained. The resulting DataFrame is assigned to df3 and displayed using show().\n\n#The DataFrame df4 is created by changing the data type of the \"salary\" column in df to String using withColumn() and cast(). The schema of df4 is printed using printSchema().\n\n#The DataFrame df is registered as a temporary view named \"PER\" using createOrReplaceTempView().\n\n#A SQL query is executed using spark.sql() to select the \"firstname\", \"gender\", and calculated \"salary\" (salary multiplied by 3) from the \"PER\" view. The result is assigned to df5 and displayed using show()."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c254ba14-f509-4567-aa21-e0f6288bbb76","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-update-column.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
