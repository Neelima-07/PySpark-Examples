{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, round\nfrom pyspark.sql.functions import to_timestamp, current_timestamp\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nschema = StructType([\n            StructField(\"input_timestamp\", StringType(), True)])\n\ndates = ['2019-07-01 12:01:19.111',\n    '2019-06-24 12:01:19.222',\n    '2019-11-16 16:44:55.406',\n    '2019-11-16 16:50:59.406']\n\ndf = spark.createDataFrame(list( zip(dates)), schema=schema)\n\ndf.withColumn('input_timestamp',to_timestamp(col('input_timestamp')))\\\n  .withColumn('current_timestamp', current_timestamp().alias('current_timestamp'))\\\n  .withColumn('DiffInSeconds',current_timestamp().cast(LongType()) - col('input_timestamp').cast(LongType()))\\\n  .withColumn('DiffInMinutes',round(col('DiffInSeconds')/60))\\\n  .withColumn('DiffInHours',round(col('DiffInSeconds')/3600))\\\n  .withColumn('DiffInDays',round(col('DiffInSeconds')/24*3600))\\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6ee26ba3-2003-43b6-847a-29bf53005c55","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-------------+-------------+-----------+-------------+\n|     input_timestamp|   current_timestamp|DiffInSeconds|DiffInMinutes|DiffInHours|   DiffInDays|\n+--------------------+--------------------+-------------+-------------+-----------+-------------+\n|2019-07-01 12:01:...|2023-06-21 16:17:...|    125381800|    2089697.0|    34828.0|  1.880727E10|\n|2019-06-24 12:01:...|2023-06-21 16:17:...|    125986600|    2099777.0|    34996.0|  1.889799E10|\n|2019-11-16 16:44:...|2023-06-21 16:17:...|    113441584|    1890693.0|    31512.0|1.70162376E10|\n|2019-11-16 16:50:...|2023-06-21 16:17:...|    113441220|    1890687.0|    31511.0| 1.7016183E10|\n+--------------------+--------------------+-------------+-------------+-----------+-------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#The code begins by importing the necessary libraries and creating a SparkSession using SparkSession.builder.appName('SparkByExamples.com').getOrCreate().\n\n#A schema is defined using StructType and StructField, specifying the name and data type of the column.\n\n#The dates list contains timestamp values as strings.\n\n#The DataFrame df is created using spark.createDataFrame(list(zip(dates)), schema=schema). The zip() function combines the elements from the dates list, and the resulting list of tuples is passed to createDataFrame() along with the specified schema.\n\n#The DataFrame operations are performed in a chain:\n\n#a. The withColumn() function is used to convert the \"input_timestamp\" column from string to timestamp format using to_timestamp(col('input_timestamp')).\n\n#b. The withColumn() function is used to add a new column named \"current_timestamp\" containing the current timestamp value using current_timestamp().alias('current_timestamp').\n\n#c. The withColumn() function is used to calculate the time difference in seconds between the \"current_timestamp\" and \"input_timestamp\" columns. It subtracts the \"input_timestamp\" column from the \"current_timestamp\" column and casts the result to LongType().\n\n#d. The withColumn() function is used to calculate the time difference in minutes by dividing the \"DiffInSeconds\" column by 60 and rounding the result using round(col('DiffInSeconds')/60).\n\n#e. The withColumn() function is used to calculate the time difference in hours by dividing the \"DiffInSeconds\" column by 3600 (60 seconds * 60 minutes) and rounding the result.\n\n#f. The withColumn() function is used to calculate the time difference in days by dividing the \"DiffInSeconds\" column by (24 * 3600) (24 hours * 60 minutes * 60 seconds) and rounding the result.\n\n#g. Finally, the show() function is called on the DataFrame to display the resulting columns and their values.\n\n#Overall, the code showcases how to manipulate and calculate time differences using PySpark DataFrame operations. It converts string timestamps to actual timestamp data types, calculates time differences in seconds, minutes, hours, and days, and displays the results in a tabular format.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4d506517-72fc-4a51-a4df-ce11afe96f7a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"timediff.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
